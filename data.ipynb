{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6f33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "import concurrent.futures as futures\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from urllib.parse import urlparse, unquote, urlunparse, parse_qs, urlencode\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af77d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_db_path = \"/Users/plandi/Downloads/DB/Art_Links.db\"  #misma carpeta\n",
    "fashion_db_path = \"/Users/plandi/Downloads/DB/Fashion_Links.db\"\n",
    "art_conn = sqlite3.connect(art_db_path) # Conectar a la base de datos SQLite\n",
    "fashion_conn = sqlite3.connect(fashion_db_path)\n",
    "\n",
    "art_df = pd.read_sql_query(\"Select * from LINKS\", art_conn)\n",
    "fashion_df = pd.read_sql_query( \"Select * from LINKS\", fashion_conn)\n",
    "\n",
    "\n",
    "# ----------------- Configuración de usuario / rutas -----------------\n",
    "# Reemplaza estos con tus dataframes reales si no se llaman así\n",
    "# art_df, fashion_df = <ya cargados>\n",
    "\n",
    "BASE_DIR = Path.cwd()\n",
    "LOG_FILE = BASE_DIR / \"download.log\"\n",
    "ART_DIR = BASE_DIR / \"Art_avatars\"\n",
    "FASHION_DIR = BASE_DIR / \"Fashion_avatars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b323fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Logging (consola + archivo) -----------------\n",
    "logger = logging.getLogger(\"avatar_downloader\")\n",
    "logger.setLevel(logging.INFO)\n",
    "fmt = logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "# Limpiar manejadores previos si se vuelve a ejecutar en un notebook\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setFormatter(fmt)\n",
    "fh = logging.FileHandler(LOG_FILE, mode=\"w\")\n",
    "fh.setFormatter(fmt)\n",
    "logger.addHandler(ch)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bca62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- Funciones de Ayuda (Helpers) -----------------\n",
    "def make_session() -> requests.Session:\n",
    "    session = requests.Session()\n",
    "    # Aumentamos la paciencia entre reintentos\n",
    "    retries = Retry(total=5, backoff_factor=1.5,  # <-- CAMBIO: Aumentado de 0.4 a 1.5\n",
    "                    status_forcelist=[429, 500, 502, 503, 504], # Quitamos 403 de aquí, ya que si nos banean, reintentar no ayuda\n",
    "                    allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\"])\n",
    "    adapter = HTTPAdapter(pool_connections=50, pool_maxsize=50, max_retries=retries)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    session.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"image/avif,image/webp,image/apng,image/*,*/*;q=0.8\",\n",
    "        \"Referer\": \"https://www.kickstarter.com/\"  # <-- CAMBIO: Añadida cabecera Referer\n",
    "    })\n",
    "    return session\n",
    "\n",
    "def get_high_res_url(url: str) -> str:\n",
    "    \"\"\"Elimina los parámetros de redimensionamiento de imagen de la cadena de consulta de una URL.\"\"\"\n",
    "    try:\n",
    "        parts = urlparse(url)\n",
    "        query_params = parse_qs(parts.query)\n",
    "        \n",
    "        # Parámetros a eliminar para obtener una resolución más alta\n",
    "        params_to_remove = ['height', 'width', 'fit', 'q']\n",
    "        for param in params_to_remove:\n",
    "            if param in query_params:\n",
    "                del query_params[param]\n",
    "                \n",
    "        # Reconstruir la cadena de consulta y la URL completa\n",
    "        new_query = urlencode(query_params, doseq=True)\n",
    "        new_parts = parts._replace(query=new_query)\n",
    "        return urlunparse(new_parts)\n",
    "    except Exception:\n",
    "        # Si el análisis falla por cualquier motivo, devuelve la URL original\n",
    "        return url\n",
    "\n",
    "_IMAGE_EXT_RE = re.compile(r\"\\.(jpe?g|png|gif|webp|bmp|svg)(?:[?#].*)?$\", re.I)\n",
    "\n",
    "def looks_like_image_url(url: str) -> bool:\n",
    "    try:\n",
    "        path = urlparse(url).path or \"\"\n",
    "        return bool(_IMAGE_EXT_RE.search(path))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def init_driver(timeout=10):\n",
    "    \"\"\"Devuelve una instancia de Chrome de undetected_chromedriver sin cabeza o None en caso de fallo.\"\"\"\n",
    "    try:\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless=new\")\n",
    "        options.add_argument(\"--disable-gpu\")\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        options.add_argument(\"--window-size=1200,800\")\n",
    "        driver = uc.Chrome(options=options)\n",
    "        driver.set_page_load_timeout(timeout)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"La inicialización del driver de Selenium falló: {e}. Se omitirá el análisis de páginas con Selenium.\")\n",
    "        return None\n",
    "\n",
    "def get_extension_from_response(response: requests.Response, url: str = \"\") -> str:\n",
    "    \"\"\"Devuelve la extensión normalizada (incluyendo el punto) usando Content-Type o como alternativa la ruta de la URL.\"\"\"\n",
    "    ct = response.headers.get(\"Content-Type\", \"\").lower()\n",
    "    if \"jpeg\" in ct or \"jpg\" in ct:\n",
    "        return \".jpg\"\n",
    "    if \"png\" in ct:\n",
    "        return \".png\"\n",
    "    if \"gif\" in ct:\n",
    "        return \".gif\"\n",
    "    if \"webp\" in ct:\n",
    "        return \".webp\"\n",
    "    if \"svg\" in ct:\n",
    "        return \".svg\"\n",
    "    if \"bmp\" in ct:\n",
    "        return \".bmp\"\n",
    "\n",
    "    # Alternativa: intentar analizar la extensión desde la URL\n",
    "    try:\n",
    "        path = unquote(urlparse(url).path or \"\")\n",
    "        ext = Path(path).suffix.lower()\n",
    "        if ext in [\".jpg\", \".jpeg\"]:\n",
    "            return \".jpg\"\n",
    "        if ext in [\".png\", \".gif\", \".webp\", \".svg\", \".bmp\"]:\n",
    "            return ext\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Última alternativa\n",
    "    return \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7582d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Extracción (Selenium + BeautifulSoup) -----------------\n",
    "def extract_image_urls(rows: List[Dict]) -> List[Tuple[int, str]]:\n",
    "    \"\"\"\n",
    "    Dadas filas = [{'project_id':..., 'creator_avatar':...}, ...],\n",
    "    devuelve una lista de (project_id, final_image_url).\n",
    "    Usa Selenium+BS solo para las filas donde el enlace no es obviamente una imagen.\n",
    "    \"\"\"\n",
    "    results: List[Tuple[int, str]] = []\n",
    "    # Intentar inicializar Selenium una vez (usado solo para enlaces que no son de imágenes)\n",
    "    driver = init_driver()\n",
    "    session = make_session()  # usado para verificar algunas URLs con HEAD de forma económica si es necesario\n",
    "\n",
    "    try:\n",
    "        iterator = rows\n",
    "        for r in tqdm(iterator, desc=\"Extrayendo URLs de imágenes\", unit=\"row\"):\n",
    "            pid = r[\"project_id\"]\n",
    "            original_url = r[\"creator_avatar\"]\n",
    "\n",
    "            # --- MODIFICACIÓN ---\n",
    "            # Obtener la versión de alta resolución de la URL eliminando los parámetros de ancho/alto\n",
    "            url = get_high_res_url(original_url)\n",
    "            \n",
    "            if not isinstance(url, str) or not url.lower().startswith(\"http\"):\n",
    "                logger.warning(f\"Omitiendo URL no válida para project_id {pid}: {url}\")\n",
    "                continue\n",
    "\n",
    "            # Si la URL ya parece una imagen, usarla directamente.\n",
    "            if looks_like_image_url(url):\n",
    "                results.append((pid, url))\n",
    "                continue\n",
    "\n",
    "            # Intentar un HEAD rápido con la sesión — a veces el enlace original redirige a una imagen\n",
    "            try:\n",
    "                head = session.head(url, timeout=6, allow_redirects=True)\n",
    "                ct = head.headers.get(\"Content-Type\", \"\").lower()\n",
    "                if ct.startswith(\"image/\"):\n",
    "                    results.append((pid, url))\n",
    "                    continue\n",
    "            except Exception:\n",
    "                # recurrir al análisis con Selenium\n",
    "                pass\n",
    "\n",
    "            # Si tenemos un driver, cargar la página e intentar encontrar una etiqueta <img>\n",
    "            img_url = None\n",
    "            if driver:\n",
    "                try:\n",
    "                    driver.get(url)\n",
    "                    time.sleep(0.25)\n",
    "                    soup = bs4.BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "                    # heurística: buscar <img> en la página, preferir imágenes con srcset o clases profile/avatar\n",
    "                    img_candidates = soup.find_all(\"img\")\n",
    "                    if img_candidates:\n",
    "                        # elegir la primera de tamaño razonable o con 'avatar'/'profile' en class/alt\n",
    "                        chosen = None\n",
    "                        for img in img_candidates:\n",
    "                            src = img.get(\"src\") or img.get(\"data-src\")\n",
    "                            if not src:\n",
    "                                continue\n",
    "                            cls = \" \".join(img.get(\"class\", [])) if img.get(\"class\") else \"\"\n",
    "                            alt = (img.get(\"alt\") or \"\").lower()\n",
    "                            if \"avatar\" in cls.lower() or \"avatar\" in alt or \"profile\" in cls.lower() or \"profile\" in alt:\n",
    "                                chosen = src\n",
    "                                break\n",
    "                        if not chosen:\n",
    "                            chosen = img_candidates[0].get(\"src\") or img_candidates[0].get(\"data-src\")\n",
    "                        img_url = chosen\n",
    "                except TimeoutException:\n",
    "                    logger.warning(f\"Timeout de Selenium al cargar {url} (proyecto {pid})\")\n",
    "                except WebDriverException as e:\n",
    "                    logger.warning(f\"Error de Selenium/WebDriver para {url} (proyecto {pid}): {e}\")\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Excepción de análisis de Selenium para {url}: {e}\")\n",
    "\n",
    "            # última alternativa: simplemente usar la URL original si no se encontró nada más\n",
    "            if not img_url:\n",
    "                logger.info(f\"No se pudo analizar un <img> para el proyecto {pid}, volviendo a la URL original.\")\n",
    "                img_url = url\n",
    "\n",
    "            results.append((pid, img_url))\n",
    "    finally:\n",
    "        try:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "        except Exception:\n",
    "            pass\n",
    "        session.close()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163d1133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Descargador -----------------\n",
    "def download_images(pairs: List[Tuple[int, str]], save_dir: Path, max_workers: int = 2):\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    session = make_session()\n",
    "\n",
    "    def _already_downloaded(pid: int) -> bool:\n",
    "        return any(save_dir.glob(f\"{pid}.*\"))\n",
    "\n",
    "    def _download_one(item: Tuple[int, str]) -> bool:\n",
    "        pid, img_url = item\n",
    "        try:\n",
    "            # --- Todo esto está DENTRO del try ---\n",
    "            if _already_downloaded(pid):\n",
    "                return True\n",
    "            \n",
    "            resp = session.get(img_url, timeout=20, stream=True)\n",
    "            resp.raise_for_status()\n",
    "\n",
    "            ext = get_extension_from_response(resp, img_url)\n",
    "            filename = f\"{pid}{ext}\"\n",
    "            filepath = save_dir / filename\n",
    "\n",
    "            if filepath.exists():\n",
    "                return True\n",
    "\n",
    "            with open(filepath, \"wb\") as fh:\n",
    "                for chunk in resp.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        fh.write(chunk)\n",
    "            \n",
    "            time.sleep(random.uniform(0.5, 2.0))\n",
    "            return True\n",
    "        # --- Los except están alineados con el try ---\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 403:\n",
    "                logger.error(f\"Falló por 403 Forbidden para project_id {pid}. Pausando para reintentar más tarde.\")\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                logger.error(f\"Falló por error HTTP para project_id {pid} ({img_url}): {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Falló por una excepción general para project_id {pid} ({img_url}): {e}\")\n",
    "            time.sleep(1)\n",
    "            return False\n",
    "\n",
    "    results = []\n",
    "    total = len(pairs)\n",
    "    with futures.ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "        futs = [ex.submit(_download_one, p) for p in pairs]\n",
    "        for f in tqdm(futures.as_completed(futs), total=total, desc=f\"Descargando en {save_dir.name}\"):\n",
    "            results.append(f.result())\n",
    "\n",
    "    session.close()\n",
    "    success = sum(1 for r in results if r)\n",
    "    logger.info(f\"Se descargaron {success} / {total} archivos en {save_dir}\")\n",
    "    return success, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b364cb",
   "metadata": {},
   "source": [
    "View Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c548368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Ejecutor principal (para un dataframe) -----------------\n",
    "def process_df(df: pd.DataFrame, folder: Path):\n",
    "    rows = df[[\"project_id\", \"creator_avatar\"]].drop_duplicates().to_dict(\"records\")\n",
    "    pairs = extract_image_urls(rows)\n",
    "    #               AQUÍ ESTÁ EL CAMBIO MÁS IMPORTANTE\n",
    "    #                    ↓\n",
    "    download_images(pairs, folder, max_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "736ac8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-02 16:57:41,859 [INFO] Iniciando descarga de avatares de Arte\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mart_df\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[1;32m      6\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIniciando descarga de avatares de Arte\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     process_df(art_df, ART_DIR)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mart_df no encontrado en globals — omitiendo descarga de Arte\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mprocess_df\u001b[0;34m(df, folder)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_df\u001b[39m(df: pd\u001b[38;5;241m.\u001b[39mDataFrame, folder: Path):\n\u001b[1;32m      3\u001b[0m     rows \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreator_avatar\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     pairs \u001b[38;5;241m=\u001b[39m extract_image_urls(rows)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#               AQUÍ ESTÁ EL CAMBIO MÁS IMPORTANTE\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#                    ↓\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     download_images(pairs, folder, max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mextract_image_urls\u001b[0;34m(rows)\u001b[0m\n\u001b[1;32m      8\u001b[0m results: List[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Intentar inicializar Selenium una vez (usado solo para enlaces que no son de imágenes)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m driver \u001b[38;5;241m=\u001b[39m init_driver()\n\u001b[1;32m     11\u001b[0m session \u001b[38;5;241m=\u001b[39m make_session()  \u001b[38;5;66;03m# usado para verificar algunas URLs con HEAD de forma económica si es necesario\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36minit_driver\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m     54\u001b[0m options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--disable-dev-shm-usage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--window-size=1200,800\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m driver \u001b[38;5;241m=\u001b[39m uc\u001b[38;5;241m.\u001b[39mChrome(options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m     57\u001b[0m driver\u001b[38;5;241m.\u001b[39mset_page_load_timeout(timeout)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m driver\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/undetected_chromedriver/__init__.py:466\u001b[0m, in \u001b[0;36mChrome.__init__\u001b[0;34m(self, options, user_data_dir, driver_executable_path, browser_executable_path, port, enable_cdp_events, desired_capabilities, advanced_elements, keep_alive, log_level, headless, version_main, patcher_force_close, suppress_welcome, use_subprocess, debug, no_sandbox, user_multi_procs, **kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbrowser_pid \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mpid\n\u001b[1;32m    462\u001b[0m service \u001b[38;5;241m=\u001b[39m selenium\u001b[38;5;241m.\u001b[39mwebdriver\u001b[38;5;241m.\u001b[39mchromium\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mChromiumService(\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatcher\u001b[38;5;241m.\u001b[39mexecutable_path\n\u001b[1;32m    464\u001b[0m )\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28msuper\u001b[39m(Chrome, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    467\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[1;32m    468\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    469\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m    470\u001b[0m )\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreactor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_cdp_events:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/selenium/webdriver/chrome/webdriver.py:47\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     44\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[1;32m     45\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     48\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     49\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m     51\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[1;32m     52\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/selenium/webdriver/chromium/webdriver.py:58\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     55\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39menv_path() \u001b[38;5;129;01mor\u001b[39;00m finder\u001b[38;5;241m.\u001b[39mget_driver_path()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     60\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[1;32m     61\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     62\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/selenium/webdriver/common/service.py:112\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# sleep increasing: 0.01, 0.06, 0.11, 0.16, 0.21, 0.26, 0.31, 0.36, 0.41, 0.46, 0.5\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m sleep(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;241m*\u001b[39m count, \u001b[38;5;241m0.5\u001b[39m))\n\u001b[1;32m    113\u001b[0m count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m70\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------------- Ejemplo de ejecución -----------------\n",
    "# Asegúrate de que art_df y fashion_df existan en el kernel.\n",
    "# Si tienen nombres diferentes, reemplaza las referencias a continuación.\n",
    "\n",
    "if \"art_df\" in globals():\n",
    "    logger.info(\"Iniciando descarga de avatares de Arte\")\n",
    "    process_df(art_df, ART_DIR)\n",
    "else:\n",
    "    logger.warning(\"art_df no encontrado en globals — omitiendo descarga de Arte\")\n",
    "\n",
    "if \"fashion_df\" in globals():\n",
    "    logger.info(\"Iniciando descarga de avatares de Moda\")\n",
    "    process_df(fashion_df, FASHION_DIR)\n",
    "else:\n",
    "    logger.warning(\"fashion_df no encontrado en globals — omitiendo descarga de Moda\")\n",
    "\n",
    "logger.info(\"Todo listo. Revisa download.log para más detalles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89eea856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pathlib import Path\n",
    "\n",
    "# Define la ruta al archivo de log\n",
    "#log_file_path = Path.cwd() / \"download.log\"\n",
    "\n",
    "# Verifica si el archivo existe y lo elimina\n",
    "#if log_file_path.exists():\n",
    "#    log_file_path.unlink()\n",
    "#    print(\"El archivo 'download.log' ha sido eliminado exitosamente.\")\n",
    "#else:\n",
    "#    print(\"El archivo 'download.log' no se encontró (ya estaba borrado).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
